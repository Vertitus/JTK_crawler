# JTK search

**Асинхронный краулер для архивных расследований.**  
Проект создан для анализа большого объёма архивированных страниц из Wayback Machine, с целью поиска редких совпадений, утраченных медиа и интернет-артефактов. Разработан с прицелом на расширяемость, эффективность и будущую визуальную аналитику.

## Возможности

- Многопоточная асинхронная обработка (на основе `aiohttp`)
- Поддержка нескольких доменов и диапазонов дат
- Пакетная обработка (batching) для памяти-эффективного кэширования
- Хэширование содержимого страниц для исключения повторов
- Расширяемая архитектура с модульным кодом
- Возможность обработки более 2 миллионов архивных страниц

## Текущие ветки

- **v1-base** — монолит, один домен, без асинхронности (эталонная базовая версия)
- **v2-async** — мультидоменная, асинхронная, но с высокой нагрузкой
- **v3-modular** — модульная, пакетная, оптимизированная по памяти (активная разработка)

## Будущее проекта

- [ ] Визуализация карты сайтов, графики частоты и повторов
- [ ] Встраивание нейросетевой фильтрации контекста (LLM-интеграция)
- [ ] Поддержка других архивов (archive.today, локальные дампы)
- [ ] CLI/GUI-интерфейс для пользовательской работы
- [ ] Возможность адаптации под другие поисковые задачи (lost media, OSINT)

## Использование (в разработке)

> Требуется Python 3.10+  
> Установка зависимостей:
